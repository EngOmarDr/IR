# src/indexing.py

import joblib
import os
from sklearn.neighbors import NearestNeighbors
import numpy as np
from scipy.sparse import issparse

def build_index(matrix_path, index_path, n_neighbors=10):
    print(f"ğŸ“¦ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØªÙ…Ø«ÙŠÙ„Ø§Øª Ù…Ù† {matrix_path} ...")
    ids, vectors = joblib.load(matrix_path)

    print(f"ğŸ” {'Sparse' if issparse(vectors) else 'Dense'} ØªÙ…Ø«ÙŠÙ„ØŒ Ø§Ø®ØªÙŠØ§Ø± algorithm Ù…Ù†Ø§Ø³Ø¨...")

    print(f"âš™ï¸ Ø¨Ù†Ø§Ø¡ ÙÙ‡Ø±Ø³ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… NearestNeighbors (n={n_neighbors}) ...")

    if issparse(vectors):
        # Ø§Ø³ØªØ®Ø¯Ù… brute Ù„Ø£Ù†Ù‡ ÙŠØ¯Ø¹Ù… sparse
        index = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine', algorithm='brute')
    else:
        # dense vector Ù…Ø«Ù„ Word2Vec Ø£Ùˆ BERT
        index = NearestNeighbors(n_neighbors=n_neighbors, metric='cosine')

    index.fit(vectors)

    print(f"ğŸ’¾ Ø­ÙØ¸ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¥Ù„Ù‰ {index_path} ...")
    os.makedirs(os.path.dirname(index_path), exist_ok=True)
    joblib.dump((ids, index), index_path)

    print("âœ… ØªÙ… Ø¨Ù†Ø§Ø¡ Ø§Ù„ÙÙ‡Ø±Ø³ Ø¨Ù†Ø¬Ø§Ø­.")
#quora
if __name__ == "__main__":
    dataset = "quora"
    vector_store = "vector_stores"

    build_index(
        matrix_path=os.path.join(vector_store, f"{dataset}_tfidf_matrix.joblib"),
        index_path=os.path.join(vector_store, f"{dataset}_tfidf_index.joblib")
    )

    build_index(
        matrix_path=os.path.join(vector_store, f"{dataset}_word2vec_vectors.joblib"),
        index_path=os.path.join(vector_store, f"{dataset}_word2vec_index.joblib")
    )

    build_index(
        matrix_path=os.path.join(vector_store, f"{dataset}_bert_vectors.joblib"),
        index_path=os.path.join(vector_store, f"{dataset}_bert_index.joblib")
    )

    build_index(
        matrix_path=os.path.join(vector_store, f"{dataset}_hybrid_vectors.joblib"),
        index_path=os.path.join(vector_store, f"{dataset}_hybrid_index.joblib")
    )